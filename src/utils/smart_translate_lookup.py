"""
@File    : smart_translate_lookup.py
@Project : OpenDataFitHou
@Date    : 2025-11-30 19:00:00
@Author  : MFitHou Team

Part of OpenDataFitHou - ·ª®ng d·ª•ng d·ªØ li·ªáu m·ªü li√™n k·∫øt ph·ª•c v·ª• chuy·ªÉn ƒë·ªïi s·ªë

Copyright (C) 2025 FITHOU

This program is free software: you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.

This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
GNU General Public License for more details.

You should have received a copy of the GNU General Public License
along with this program. If not, see <https://www.gnu.org/licenses/>.
"""

import re
import json
import os
import time
import requests
from typing import Optional, Dict, Tuple
import unicodedata

class SmartTranslator:
    """
    Intelligent translator using Wikidata API with caching and pattern-based fallback.
    """
    
    def __init__(self, cache_file: str = "translation_cache.json"):
        """
        Initialize the translator with cache support.
        
        Args:
            cache_file: Path to JSON cache file
        """
        self.cache_file = cache_file
        self.cache = self._load_cache()
        self.api_call_count = 0
        self.cache_hit_count = 0
        
        # Wikidata API endpoint
        self.wikidata_api = "https://www.wikidata.org/w/api.php"
        
        # Generic prefixes to remove (often found in OSM but not official names)
        self.prefixes_to_remove = [
            r'^ƒê·ªãa\s+ch·ªâ:\s*',
            r'^S·ªë\s+\d+\s*',
            r'^Tr·ª•\s+s·ªü\s+',
            r'^VƒÉn\s+ph√≤ng\s+',
            r'^Chi\s+nh√°nh\s+',
        ]
        
        # Abbreviation standardization
        self.abbreviations = {
            r'\bƒêH\b': 'ƒê·∫°i h·ªçc',
            r'\bTHPT\b': 'Tr∆∞·ªùng Trung h·ªçc ph·ªï th√¥ng',
            r'\bTHCS\b': 'Tr∆∞·ªùng Trung h·ªçc c∆° s·ªü',
            r'\bTH\b': 'Tr∆∞·ªùng Ti·ªÉu h·ªçc',
            r'\bMN\b': 'Tr∆∞·ªùng M·∫ßm non',
            r'\bBV\b': 'B·ªánh vi·ªán',
            r'\bTT\b': 'Trung t√¢m',
            r'\bCty\b': 'C√¥ng ty',
            r'\bUBND\b': '·ª¶y ban Nh√¢n d√¢n',
            r'\bTP\b': 'Th√†nh ph·ªë',
            r'\bQ\.\s*': 'Qu·∫≠n ',
            r'\bP\.\s*': 'Ph∆∞·ªùng ',
            r'\bPGD\b': 'Ph√≤ng Gi√°o d·ª•c',
        }
        
        # Pattern-based translation rules for common structures
        self.pattern_translations = [
            # Administrative units
            (r'^·ª¶y\s+ban\s+Nh√¢n\s+d√¢n\s+(.+)$', r'People\'s Committee of \1'),
            (r'^UBND\s+(.+)$', r'People\'s Committee of \1'),
            (r'^Nh√†\s+vƒÉn\s+h√≥a\s+(.+)$', r'Cultural House of \1'),
            (r'^T·ªï\s+d√¢n\s+ph·ªë\s+(\d+)$', r'Residential Group \1'),
            (r'^Khu\s+d√¢n\s+c∆∞\s+(.+)$', r'Residential Area \1'),
            
            # Education patterns
            (r'^Tr∆∞·ªùng\s+ƒê·∫°i\s+h·ªçc\s+(.+)$', r'\1 University'),
            (r'^ƒê·∫°i\s+h·ªçc\s+(.+)$', r'\1 University'),
            (r'^Tr∆∞·ªùng\s+Trung\s+h·ªçc\s+ph·ªï\s+th√¥ng\s+(.+)$', r'\1 High School'),
            (r'^Tr∆∞·ªùng\s+THPT\s+(.+)$', r'\1 High School'),
            (r'^Tr∆∞·ªùng\s+Trung\s+h·ªçc\s+c∆°\s+s·ªü\s+(.+)$', r'\1 Secondary School'),
            (r'^Tr∆∞·ªùng\s+THCS\s+(.+)$', r'\1 Secondary School'),
            (r'^Tr∆∞·ªùng\s+Ti·ªÉu\s+h·ªçc\s+(.+)$', r'\1 Primary School'),
            (r'^Tr∆∞·ªùng\s+M·∫ßm\s+non\s+(.+)$', r'\1 Kindergarten'),
            (r'^Th∆∞\s+vi·ªán\s+(.+)$', r'\1 Library'),
            
            # Medical patterns
            (r'^B·ªánh\s+vi·ªán\s+(.+)$', r'\1 Hospital'),
            (r'^Ph√≤ng\s+kh√°m\s+(.+)$', r'\1 Clinic'),
            (r'^Nh√†\s+thu·ªëc\s+(.+)$', r'\1 Pharmacy'),
            (r'^Trung\s+t√¢m\s+Y\s+t·∫ø\s+(.+)$', r'\1 Medical Center'),
            
            # Emergency services
            (r'^ƒê·ªìn\s+C√¥ng\s+an\s+(.+)$', r'\1 Police Station'),
            (r'^C√¥ng\s+an\s+(.+)$', r'\1 Police'),
            (r'^Tr·∫°m\s+C·ª©u\s+h·ªèa\s+(.+)$', r'\1 Fire Station'),
            
            # Commercial patterns
            (r'^Ng√¢n\s+h√†ng\s+(.+)$', r'\1 Bank'),
            (r'^Si√™u\s+th·ªã\s+(.+)$', r'\1 Supermarket'),
            (r'^C·ª≠a\s+h√†ng\s+(.+)$', r'\1 Store'),
            (r'^Nh√†\s+h√†ng\s+(.+)$', r'\1 Restaurant'),
            (r'^Qu√°n\s+(.+)$', r'\1 Shop'),
            (r'^Ch·ª£\s+(.+)$', r'\1 Market'),
            (r'^B∆∞u\s+ƒëi·ªán\s+(.+)$', r'\1 Post Office'),
            
            # Infrastructure
            (r'^C√¥ng\s+vi√™n\s+(.+)$', r'\1 Park'),
            (r'^B√£i\s+ƒë·ªó\s+xe\s+(.+)$', r'\1 Parking'),
            (r'^Tr·∫°m\s+xe\s+bu√Ωt\s+(.+)$', r'\1 Bus Stop'),
            (r'^Tr·∫°m\s+xƒÉng\s+(.+)$', r'\1 Gas Station'),
        ]
        
        # Special cases dictionary (for well-known entities)
        self.special_cases = {
            'ƒê·∫°i h·ªçc Qu·ªëc gia H√† N·ªôi': 'Vietnam National University, Hanoi',
            'ƒê·∫°i h·ªçc B√°ch khoa H√† N·ªôi': 'Hanoi University of Science and Technology',
            'ƒê·∫°i h·ªçc Ki·ªÉm s√°t H√† N·ªôi': 'Hanoi Procuratorate University',
            'B·ªánh vi·ªán B·∫°ch Mai': 'Bach Mai Hospital',
            'B·ªánh vi·ªán Vi·ªát ƒê·ª©c': 'Viet Duc Hospital',
            'B·ªánh vi·ªán K': 'K Hospital',
            'B·ªánh vi·ªán Nhi Trung ∆∞∆°ng': 'National Children\'s Hospital',
            'H·ªì Ho√†n Ki·∫øm': 'Hoan Kiem Lake',
            'Ch·ª£ ƒê·ªìng Xu√¢n': 'Dong Xuan Market',
        }
    
    def _load_cache(self) -> Dict[str, str]:
        """Load translation cache from JSON file."""
        if os.path.exists(self.cache_file):
            try:
                with open(self.cache_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                print(f"Warning: Could not load cache: {e}")
                return {}
        return {}
    
    def _save_cache(self):
        """Save translation cache to JSON file."""
        try:
            with open(self.cache_file, 'w', encoding='utf-8') as f:
                json.dump(self.cache, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"Warning: Could not save cache: {e}")
    
    def _normalize_vietnamese_name(self, name: str) -> str:
        """
        Normalize Vietnamese name before searching.
        
        Args:
            name: Original Vietnamese name
            
        Returns:
            Normalized name
        """
        if not name:
            return name
        
        # Remove generic prefixes
        for prefix_pattern in self.prefixes_to_remove:
            name = re.sub(prefix_pattern, '', name, flags=re.IGNORECASE)
        
        # Expand abbreviations
        for abbr, full in self.abbreviations.items():
            name = re.sub(abbr, full, name, flags=re.IGNORECASE)
        
        # Clean up whitespace
        name = ' '.join(name.split())
        
        return name.strip()
    
    def _search_wikidata(self, vi_name: str) -> Optional[str]:
        """
        Search Wikidata for English translation.
        
        Args:
            vi_name: Vietnamese name to search
            
        Returns:
            English name if found, None otherwise
        """
        try:
            # Wikidata search parameters
            params = {
                'action': 'wbsearchentities',
                'format': 'json',
                'language': 'vi',
                'search': vi_name,
                'limit': 5
            }
            
            # Rate limiting: max 1 request per second
            time.sleep(1)
            
            response = requests.get(self.wikidata_api, params=params, timeout=10)
            response.raise_for_status()
            
            data = response.json()
            self.api_call_count += 1
            
            # Check if we have results
            if 'search' in data and len(data['search']) > 0:
                # Get the first result (most relevant)
                entity_id = data['search'][0]['id']
                
                # Fetch entity details to get English label
                entity_params = {
                    'action': 'wbgetentities',
                    'format': 'json',
                    'ids': entity_id,
                    'props': 'labels',
                    'languages': 'en'
                }
                
                time.sleep(1)
                entity_response = requests.get(self.wikidata_api, params=entity_params, timeout=10)
                entity_response.raise_for_status()
                
                entity_data = entity_response.json()
                
                # Extract English label
                if 'entities' in entity_data and entity_id in entity_data['entities']:
                    entity = entity_data['entities'][entity_id]
                    if 'labels' in entity and 'en' in entity['labels']:
                        return entity['labels']['en']['value']
            
            return None
            
        except Exception as e:
            print(f"  Wikidata search failed for '{vi_name}': {e}")
            return None
    
    def _pattern_based_translation(self, vi_name: str) -> Optional[str]:
        """
        Apply pattern-based translation rules.
        
        Args:
            vi_name: Vietnamese name
            
        Returns:
            English translation if pattern matches, None otherwise
        """
        for pattern, replacement in self.pattern_translations:
            match = re.match(pattern, vi_name, flags=re.IGNORECASE)
            if match:
                # Apply the translation pattern
                result = re.sub(pattern, replacement, vi_name, flags=re.IGNORECASE)
                # Remove Vietnamese accents from the remaining parts
                result = self._transliterate_vietnamese(result)
                return result
        
        return None
    
    def _transliterate_vietnamese(self, text: str) -> str:
        """
        Transliterate Vietnamese text to ASCII (remove accents).
        
        Args:
            text: Vietnamese text
            
        Returns:
            Text without accents
        """
        # Normalize and remove accents
        nfd = unicodedata.normalize('NFD', text)
        result = ''.join([c for c in nfd if not unicodedata.combining(c)])
        
        # Handle special Vietnamese characters
        replacements = {
            'ƒë': 'd', 'ƒê': 'D',
            '√∞': 'd', '√ê': 'D'
        }
        
        for viet_char, eng_char in replacements.items():
            result = result.replace(viet_char, eng_char)
        
        return result
    
    def get_official_english_name(self, vi_name: str) -> Tuple[str, str]:
        """
        Get official English name for a Vietnamese POI name.
        
        Strategy:
        1. Check special cases dictionary
        2. Check cache
        3. Normalize Vietnamese name
        4. Search Wikidata API
        5. Apply pattern-based translation
        6. Fallback to transliteration
        
        Args:
            vi_name: Vietnamese name to translate
            
        Returns:
            Tuple of (english_name, source) where source is one of:
            'special', 'cache', 'wikidata', 'pattern', 'transliterate'
        """
        if not vi_name:
            return (vi_name, 'empty')
        
        original_name = vi_name.strip()
        
        # Strategy 1: Check special cases
        if original_name in self.special_cases:
            return (self.special_cases[original_name], 'special')
        
        # Strategy 2: Check cache
        if original_name in self.cache:
            self.cache_hit_count += 1
            return (self.cache[original_name], 'cache')
        
        # Strategy 3: Normalize name
        normalized_name = self._normalize_vietnamese_name(original_name)
        
        # Strategy 4: Search Wikidata
        wikidata_result = self._search_wikidata(normalized_name)
        if wikidata_result:
            # Cache the result
            self.cache[original_name] = wikidata_result
            self._save_cache()
            return (wikidata_result, 'wikidata')
        
        # Strategy 5: Pattern-based translation
        pattern_result = self._pattern_based_translation(normalized_name)
        if pattern_result:
            # Cache the result
            self.cache[original_name] = pattern_result
            self._save_cache()
            return (pattern_result, 'pattern')
        
        # Strategy 6: Fallback to transliteration
        transliterated = self._transliterate_vietnamese(normalized_name)
        self.cache[original_name] = transliterated
        self._save_cache()
        return (transliterated, 'transliterate')
    
    def get_stats(self) -> Dict[str, int]:
        """
        Get translation statistics.
        
        Returns:
            Dictionary with stats
        """
        return {
            'cache_size': len(self.cache),
            'cache_hits': self.cache_hit_count,
            'api_calls': self.api_call_count,
            'cache_file': self.cache_file
        }


# Convenience function for quick usage
def translate_to_english(vi_name: str, translator: Optional[SmartTranslator] = None) -> str:
    """
    Quick translation function.
    
    Args:
        vi_name: Vietnamese name to translate
        translator: Existing translator instance (optional)
        
    Returns:
        English translation
    """
    if translator is None:
        translator = SmartTranslator()
    
    result, source = translator.get_official_english_name(vi_name)
    return result


# Test function
def test_translator():
    """Test the translator with sample names."""
    print("="*80)
    print("Smart Translator - Test Suite")
    print("="*80)
    
    translator = SmartTranslator()
    
    test_cases = [
        "Tr∆∞·ªùng ƒê·∫°i h·ªçc Ki·ªÉm s√°t H√† N·ªôi",
        "B·ªánh vi·ªán B·∫°ch Mai",
        "UBND Ph∆∞·ªùng Ho√†n Ki·∫øm",
        "Nh√† vƒÉn h√≥a T·ªï 5",
        "T·ªï d√¢n ph·ªë 12",
        "Tr∆∞·ªùng THPT Chu VƒÉn An",
        "Si√™u th·ªã Vinmart",
        "Ch·ª£ ƒê·ªìng Xu√¢n",
    ]
    
    for test_name in test_cases:
        english_name, source = translator.get_official_english_name(test_name)
        print(f"\nüìç Vietnamese: {test_name}")
        print(f"   English: {english_name}")
        print(f"   Source: {source}")
    
    print("\n" + "="*80)
    print("Translation Statistics:")
    stats = translator.get_stats()
    for key, value in stats.items():
        print(f"  {key}: {value}")
    print("="*80)


if __name__ == "__main__":
    test_translator()
